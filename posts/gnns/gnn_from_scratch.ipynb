{
 "cells": [
  {
   "cell_type": "raw",
   "id": "275b92e3",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Implementing a Graph Neural Network from Scratch\"\n",
    "description: \"In this notebook we'll try to implement a simple message passing neural network (Graph Convolution Layer) from scratch, and a step-by-step introduction to the topic.\"\n",
    "author: \"Shubham Shinde\"\n",
    "date: \"01/25/2022\"\n",
    "categories:\n",
    "  - deep-learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57149734",
   "metadata": {},
   "source": [
    "![Let's Build a GNN](graph_cat.jpg){width=50%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d14df4",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shindeshu/gnn_from_scratch.ipynb)\n",
    "\n",
    "If you are unfamiliar with GNNs in general, please go through my small [intro blogpost](https://shindeshu.github.io/posts/gnns/intro_gnn.html). Message Passing is one of the more popular concepts in GNNs, and that is what we'll try to implement here. Specifically we are implementing the Graph Convolutional Layer/Network proposed by Kipf et al in 2016. You can go through a detailed [blogpost](https://tkipf.github.io/graph-convolutional-networks/) of his or the [original paper](https://arxiv.org/abs/1609.02907)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf89cb",
   "metadata": {},
   "source": [
    "## Representing a Graph\n",
    "\n",
    "Before we start on to Graph convolutions, let's first present it out on how do we represent a graph in code. Mathematically, a graph is defined as a tuple of a set of nodes/vertices <img src=\"https://render.githubusercontent.com/render/math?math=V\">, and a set of edges/links <img src=\"https://render.githubusercontent.com/render/math?math=E:\\mathcal{G}=(V,E)\">. Further, each edge is a pair of two vertices, and represents a connection between them.\n",
    "\n",
    "Visually, a graph would look something like this: \n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"https://www.researchgate.net/profile/Wei-Dong-51/publication/235973074/figure/fig1/AS:393538677297153@1470838340530/A-small-example-graph-representation-of-a-network-with-8-nodes-and-14-undirected-edges.png\" width=\"350px\"></center>\n",
    "\n",
    "The vertices are <img src=\"https://render.githubusercontent.com/render/math?math=V=\\{1,2,3,4,5,6,7,8\\}\">, and edges <img src=\"https://render.githubusercontent.com/render/math?math=E=\\{(1,5), (2,1), (2,8), (3,4), ...\\}\">.\n",
    "\n",
    "There are many ways to represent graphs in memory- two of them include \"adjacency matrix\" ($a$) and \"edge list\". If the number of nodes is $n$, the adjacency matrix is $n x n$. If there's an edge from node $n_i$ to $n_j$, the element $a_{ij}$ is equal to 1. Likewise, the other elements of $a$ are populated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccffce",
   "metadata": {},
   "source": [
    "```python\n",
    "[[ 0 1 0 0 ]\n",
    " [ 1 0 1 1 ]\n",
    " [ 0 1 0 1 ]\n",
    " [ 0 1 1 0 ]]\n",
    "```\n",
    "\n",
    "Working with adjacency matrix for graph operations is easier, although they have their limitations. While established libraries like ```dgl``` or ```pytorch-geometric``` use edge-list format of data, here we are working with an adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272eb9df",
   "metadata": {},
   "source": [
    "## Graph Convolutions\n",
    "\n",
    "Graph convolutions are somewhat similar to image convolutions, in that they take their neighbourhood information and aggregate to get a richer understanding of their position. Also, the \"parameters\" of the filters are shared across the entire image, which is analogous to a graph convolution as well, where the parameters are shared across the graph.\n",
    "\n",
    "GCNs rely on the message passing paradigm. Each node has a feature vector associated with it. For a given node u, each of its neighbouring nodes $v_i$ send a message derived from its feature vector to it. All these messages are aggregated alongwith its own feature vector, and this is used to update this node $u$ to get the final feature vector (or embedding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82747ce",
   "metadata": {},
   "source": [
    "## Current Implementation \n",
    "\n",
    "Each node has a feature vector. This feature will be projected using a linear layer, output of which will be the message that each node passes. We will represent the graph as an adjacency matrix, and multiply by the node features (projected) to perform the message passing. This will be divided by the number of neighbours for normalizing, which will give us the output of our first graph convolution layer.\n",
    "\n",
    "Importing all our libraries. We are not using libraries like ```dgl``` or ```pytorch-geometric```, we will be using plain pytorch. We are also using ```networkx``` for manipulating graph.\n",
    "\n",
    "We will be a creating a random matrix as an adjacency matrix. Creating a matrix with uniform_ method and the bernoulli method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 10\n",
    "node_features_size = 4\n",
    "\n",
    "adj = torch.empty(nodes, nodes).uniform_(0, 1).bernoulli()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a37b32",
   "metadata": {},
   "source": [
    "Visualizing the graph we created with networkx library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73153bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.from_numpy_matrix(adj.numpy())\n",
    "graph.remove_edges_from(nx.selfloop_edges(graph))\n",
    "\n",
    "pos = nx.kamada_kawai_layout(graph)\n",
    "nx.draw(graph, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ff70f",
   "metadata": {},
   "source": [
    "![png](gnn_from_scratch_files/gnn_from_scratch_12_0.png)\n",
    "\n",
    "Creating random features for our nodes. These features will go through a dense layer and then act as our messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = torch.empty(nodes, node_features_size).uniform_(0, 1).bernoulli()#.view(1, nodes, node_features_size)\n",
    "node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5630d2",
   "metadata": {},
   "source": [
    "The features will pass through a linear layer to create our messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc52e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector = nn.Linear(node_features_size, 5)\n",
    "\n",
    "node_feat_proj = projector(node_features)\n",
    "\n",
    "num_neighbours = adj.sum(dim=-1, keepdims=True)\n",
    "\n",
    "torch.matmul(adj, node_feat_proj)/num_neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a218ec6",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[-0.5067, -0.2463, -0.0555,  0.2188,  0.4031],\n",
    "            [-0.8397,  0.0945,  0.5124,  0.1179, -0.0296],\n",
    "            [-0.6457,  0.2369,  0.5048, -0.0216,  0.1531],\n",
    "            [-0.9893,  0.4223,  0.7235,  0.3212, -0.1165],\n",
    "            [-0.5876,  0.2246,  0.5227, -0.1519,  0.1979],\n",
    "            [-0.6133, -0.0359,  0.2532,  0.0760,  0.2250],\n",
    "            [-0.7740,  0.2055,  0.5252,  0.1075,  0.0174],\n",
    "            [-0.7827,  0.1653,  0.5654,  0.0135, -0.0155],\n",
    "            [-0.8635,  0.3189,  0.6940,  0.0758, -0.0423],\n",
    "            [-0.9374,  0.2670,  0.6672,  0.1805, -0.1292]], grad_fn=<DivBackward0>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124921e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj.shape, node_feat_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a32ea",
   "metadata": {},
   "source": [
    "```\n",
    "(torch.Size([10, 10]), torch.Size([10, 5]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc16f35",
   "metadata": {},
   "source": [
    "## A Note on Above Multiplication Operation\n",
    "\n",
    "How it does achieve our objective, i.e. summing up of messages from neighbouring nodes of a particular node?\n",
    "\n",
    "For simplicity, lets take an example where the adj matrix is $ 7 \\times 7$ and the message matrix is $ 7 \\times 5 $.\n",
    "\n",
    "Consider a single row from the adjacency matrix, that corresponds to a node $n_i$. It might look something like\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "    0 & 1 & 0 & 0 & 1 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And the message matrix is $7 \\times 5$. (seven rows, five columns).\n",
    "\n",
    "For this node, we can observe there are edges existent only for nodes ${2, 5, 7}$. When we multiple the above matrix with the message/feature matrix, we will get the elements corresponding to those indexes summed up (since others are multiplied by zero), along the second axis of the feature matrix i.e. we will get a $1 \\times 5$ size vector.\n",
    "\n",
    "Here, you can see that only the neighbouring nodes' features have been summed up to get the final d-length vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba815827",
   "metadata": {},
   "source": [
    "## Putting It All Together\n",
    "\n",
    "Now that we've done it step-by-step, let us aggregate the operations together in proper functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.projector = nn.Linear(in_feat, out_feat)\n",
    "\n",
    "    def forward(self, node_features, adj):\n",
    "        num_neighbours = adj.sum(dim=-1, keepdims=True)\n",
    "        node_features = torch.relu(self.projector(node_features))\n",
    "        node_features = torch.matmul(adj, node_features)\n",
    "        node_features = node_features / num_neighbours\n",
    "        node_features = torch.relu(node_features)\n",
    "        return node_features\n",
    "layer1 = GCNLayer(node_features_size, 8)\n",
    "layer1(node_features, adj).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e6a4f",
   "metadata": {},
   "source": [
    "```\n",
    "torch.Size([10, 8])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = GCNLayer(8, 2)\n",
    "layer2(layer1(node_features, adj), adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd16137",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[0.4279, 0.4171],\n",
    "            [0.4724, 0.4304],\n",
    "            [0.4318, 0.3761],\n",
    "            [0.4315, 0.3860],\n",
    "            [0.4520, 0.4132],\n",
    "            [0.4449, 0.4049],\n",
    "            [0.4346, 0.3827],\n",
    "            [0.4614, 0.4176],\n",
    "            [0.4446, 0.3860],\n",
    "            [0.4068, 0.3582]], grad_fn=<ReluBackward0>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNmodel(nn.Module):\n",
    "    def __init__(self, in_feat, hid_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.gcn_layer1 = GCNLayer(in_feat, hid_feat)\n",
    "        self.gcn_layer2 = GCNLayer(hid_feat, out_feat)\n",
    "\n",
    "    def forward(self, node_features, adj):\n",
    "        h = self.gcn_layer1(node_features, adj)\n",
    "        h = self.gcn_layer2(h, adj)\n",
    "        return h\n",
    "model = GCNmodel(node_features_size, 12, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860a6a0",
   "metadata": {},
   "source": [
    "## Solving a Real Problem\n",
    "\n",
    "Now that we are able to play around with random data, lets us get to work on some real datasets that we can do basic classification problems on. We will be using the zachary's karate club dataset, which is a small dataset of 34 people and the edges include their observed interactions with each other. Our objective: predict which group will each of the people go to once their club is bisected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973167a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_karate_club_graph():\n",
    "    g = nx.Graph()\n",
    "    edge_list = [(1, 0), (2, 0), (2, 1), (3, 0), (3, 1), (3, 2),\n",
    "        (4, 0), (5, 0), (6, 0), (6, 4), (6, 5), (7, 0), (7, 1),\n",
    "        (7, 2), (7, 3), (8, 0), (8, 2), (9, 2), (10, 0), (10, 4),\n",
    "        (10, 5), (11, 0), (12, 0), (12, 3), (13, 0), (13, 1), (13, 2),\n",
    "        (13, 3), (16, 5), (16, 6), (17, 0), (17, 1), (19, 0), (19, 1),\n",
    "        (21, 0), (21, 1), (25, 23), (25, 24), (27, 2), (27, 23),\n",
    "        (27, 24), (28, 2), (29, 23), (29, 26), (30, 1), (30, 8),\n",
    "        (31, 0), (31, 24), (31, 25), (31, 28), (32, 2), (32, 8),\n",
    "        (32, 14), (32, 15), (32, 18), (32, 20), (32, 22), (32, 23),\n",
    "        (32, 29), (32, 30), (32, 31), (33, 8), (33, 9), (33, 13),\n",
    "        (33, 14), (33, 15), (33, 18), (33, 19), (33, 20), (33, 22),\n",
    "        (33, 23), (33, 26), (33, 27), (33, 28), (33, 29), (33, 30),\n",
    "        (33, 31), (33, 32)]\n",
    "    g.add_edges_from(edge_list)\n",
    "    return g\n",
    "\n",
    "g = build_karate_club_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653671d",
   "metadata": {},
   "source": [
    "Visualizing our karate club graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(g)\n",
    "nx.draw(g, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b4148",
   "metadata": {},
   "source": [
    "![png](gnn_from_scratch_files/gnn_from_scratch_35_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e724c87",
   "metadata": {},
   "source": [
    "We don't have any node features. So here we're creating a one-hot vector for each node based on its id. Together, it'd be a single identity matrix for the graph.\n",
    "\n",
    "At the beginning, only the instructor and president nodes are labelled. Later on each person will join one of the groups headed by these two. So it's a binary classification, and the only labeled nodes we have are two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9447cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features =  torch.eye(34) \n",
    "labeled_nodes = torch.tensor([0, 33])  # only the instructor and the president nodes are labeled\n",
    "labels = torch.tensor([0, 1])\n",
    "\n",
    "# since our code only works on adjacency matrix and not on edge-list\n",
    "\n",
    "adj_matrix = torch.from_numpy(nx.adjacency_matrix(g).todense()).float()\n",
    "\n",
    "# define our gcn model\n",
    "\n",
    "model = GCNmodel(34, 32, 2)\n",
    "\n",
    "# do a single pass just for a check\n",
    "\n",
    "model(node_features, adj_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138adab",
   "metadata": {},
   "source": [
    "Lets get to the meat of it: time to train our model. We create the usual pytorch pipeline. If you've worked with pytorch before, this is familiar to you. Even if not, you can get a certain idea if you know some basics of neural networks / backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "all_logits = []\n",
    "for epoch in range(100):\n",
    "    logits = model(node_features, adj_matrix)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb717cda",
   "metadata": {},
   "source": [
    "```\n",
    "    Epoch 0 | Loss: 0.6887\n",
    "    Epoch 1 | Loss: 0.6823\n",
    "    Epoch 2 | Loss: 0.6756\n",
    "    Epoch 3 | Loss: 0.6704\n",
    "    Epoch 4 | Loss: 0.6653\n",
    "    Epoch 5 | Loss: 0.6592\n",
    "    Epoch 6 | Loss: 0.6529\n",
    "    Epoch 7 | Loss: 0.6465\n",
    "    Epoch 8 | Loss: 0.6396\n",
    "    Epoch 9 | Loss: 0.6320\n",
    "    Epoch 10 | Loss: 0.6239\n",
    "    Epoch 11 | Loss: 0.6151\n",
    "    Epoch 12 | Loss: 0.6064\n",
    "    Epoch 13 | Loss: 0.5973\n",
    "    Epoch 14 | Loss: 0.5878\n",
    "    Epoch 15 | Loss: 0.5783\n",
    "    Epoch 16 | Loss: 0.5686\n",
    "    Epoch 17 | Loss: 0.5585\n",
    "    Epoch 18 | Loss: 0.5482\n",
    "    Epoch 19 | Loss: 0.5382\n",
    "    Epoch 20 | Loss: 0.5281\n",
    "    Epoch 21 | Loss: 0.5182\n",
    "    Epoch 22 | Loss: 0.5085\n",
    "    Epoch 23 | Loss: 0.4990\n",
    "    Epoch 24 | Loss: 0.4899\n",
    "    Epoch 25 | Loss: 0.4810\n",
    "    Epoch 26 | Loss: 0.4725\n",
    "    Epoch 27 | Loss: 0.4642\n",
    "    Epoch 28 | Loss: 0.4560\n",
    "    Epoch 29 | Loss: 0.4477\n",
    "    Epoch 30 | Loss: 0.4397\n",
    "    Epoch 31 | Loss: 0.4331\n",
    "    Epoch 32 | Loss: 0.4267\n",
    "    Epoch 33 | Loss: 0.4204\n",
    "    Epoch 34 | Loss: 0.4143\n",
    "    Epoch 35 | Loss: 0.4082\n",
    "    Epoch 36 | Loss: 0.4037\n",
    "    Epoch 37 | Loss: 0.3994\n",
    "    Epoch 38 | Loss: 0.3952\n",
    "    Epoch 39 | Loss: 0.3911\n",
    "    Epoch 40 | Loss: 0.3873\n",
    "    Epoch 41 | Loss: 0.3837\n",
    "    Epoch 42 | Loss: 0.3802\n",
    "    Epoch 43 | Loss: 0.3767\n",
    "    Epoch 44 | Loss: 0.3733\n",
    "    Epoch 45 | Loss: 0.3698\n",
    "    Epoch 46 | Loss: 0.3670\n",
    "    Epoch 47 | Loss: 0.3655\n",
    "    Epoch 48 | Loss: 0.3638\n",
    "    Epoch 49 | Loss: 0.3620\n",
    "    Epoch 50 | Loss: 0.3602\n",
    "    Epoch 51 | Loss: 0.3586\n",
    "    Epoch 52 | Loss: 0.3571\n",
    "    Epoch 53 | Loss: 0.3573\n",
    "    Epoch 54 | Loss: 0.3564\n",
    "    Epoch 55 | Loss: 0.3544\n",
    "    Epoch 56 | Loss: 0.3542\n",
    "    Epoch 57 | Loss: 0.3539\n",
    "    Epoch 58 | Loss: 0.3536\n",
    "    Epoch 59 | Loss: 0.3533\n",
    "    Epoch 60 | Loss: 0.3529\n",
    "    Epoch 61 | Loss: 0.3525\n",
    "    Epoch 62 | Loss: 0.3522\n",
    "    Epoch 63 | Loss: 0.3518\n",
    "    Epoch 64 | Loss: 0.3514\n",
    "    Epoch 65 | Loss: 0.3511\n",
    "    Epoch 66 | Loss: 0.3508\n",
    "    Epoch 67 | Loss: 0.3505\n",
    "    Epoch 68 | Loss: 0.3502\n",
    "    Epoch 69 | Loss: 0.3504\n",
    "    Epoch 70 | Loss: 0.3498\n",
    "    Epoch 71 | Loss: 0.3497\n",
    "    Epoch 72 | Loss: 0.3439\n",
    "    Epoch 73 | Loss: 0.3194\n",
    "    Epoch 74 | Loss: 0.2869\n",
    "    Epoch 75 | Loss: 0.2505\n",
    "    Epoch 76 | Loss: 0.2138\n",
    "    Epoch 77 | Loss: 0.1789\n",
    "    Epoch 78 | Loss: 0.1476\n",
    "    Epoch 79 | Loss: 0.1206\n",
    "    Epoch 80 | Loss: 0.0984\n",
    "    Epoch 81 | Loss: 0.0811\n",
    "    Epoch 82 | Loss: 0.0682\n",
    "    Epoch 83 | Loss: 0.0587\n",
    "    Epoch 84 | Loss: 0.0516\n",
    "    Epoch 85 | Loss: 0.0459\n",
    "    Epoch 86 | Loss: 0.0407\n",
    "    Epoch 87 | Loss: 0.0356\n",
    "    Epoch 88 | Loss: 0.0307\n",
    "    Epoch 89 | Loss: 0.0262\n",
    "    Epoch 90 | Loss: 0.0223\n",
    "    Epoch 91 | Loss: 0.0191\n",
    "    Epoch 92 | Loss: 0.0164\n",
    "    Epoch 93 | Loss: 0.0142\n",
    "    Epoch 94 | Loss: 0.0124\n",
    "    Epoch 95 | Loss: 0.0111\n",
    "    Epoch 96 | Loss: 0.0101\n",
    "    Epoch 97 | Loss: 0.0093\n",
    "    Epoch 98 | Loss: 0.0087\n",
    "    Epoch 99 | Loss: 0.0081\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02837f",
   "metadata": {},
   "source": [
    "We can see the loss converging. This dataset doesn't really have a valid set or anything, so there are no metrics to be presented here. But we can visualize them directly which can be fun to see. Here, we can create an animation of the results of each epoch, and watch them fluctuate as the model converges.\n",
    "\n",
    "This vis code was taken from [dgl documentation](https://docs.dgl.ai/en/0.2.x/tutorials/basics/1_first.html). The dgl docs are a great place to start learning about graph neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7126ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw(i):\n",
    "    cls1color = '#00FFFF'\n",
    "    cls2color = '#FF00FF'\n",
    "    pos = {}\n",
    "    colors = []\n",
    "    for v in range(34):\n",
    "        pos[v] = all_logits[i][v].numpy()\n",
    "        cls = pos[v].argmax()\n",
    "        colors.append(cls1color if cls else cls2color)\n",
    "    ax.cla()\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Epoch: %d' % i)\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "    nx.draw_networkx(g.to_undirected(), pos, node_color=colors,\n",
    "            with_labels=True, node_size=300, ax=ax)\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "fig.clf()\n",
    "ax = fig.subplots()\n",
    "draw(0)  # draw the prediction of the first epoch\n",
    "plt.close()\n",
    "\n",
    "ani = animation.FuncAnimation(fig, draw, frames=len(all_logits), interval=200)\n",
    "\n",
    "ani.save(\"karate.gif\", writer=\"pillow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
