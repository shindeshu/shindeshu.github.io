<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Shubham Shinde">
<meta name="dcterms.date" content="2023-01-15">
<meta name="description" content="A basic intro to CNNs, a code-only tutorial using keras">

<title>Shubham Shinde - A Friendly ☺️ Introduction to CNNs with Keras</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-E3Z2GSDBB7"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-E3Z2GSDBB7', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Shubham Shinde - A Friendly ☺️ Introduction to CNNs with Keras">
<meta property="og:description" content="A basic intro to CNNs, a code-only tutorial using keras">
<meta property="og:site-name" content="Shubham Shinde">
<meta name="twitter:title" content="Shubham Shinde - A Friendly ☺️ Introduction to CNNs with Keras">
<meta name="twitter:description" content="A basic intro to CNNs, a code-only tutorial using keras">
<meta name="twitter:creator" content="@ShindeShubham85">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Shubham Shinde</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">Home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">About</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html">Blog</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#computer-vision" id="toc-computer-vision" class="nav-link active" data-scroll-target="#computer-vision">Computer Vision</a>
  <ul class="collapse">
  <li><a href="#difference-from-traditional-modeling" id="toc-difference-from-traditional-modeling" class="nav-link" data-scroll-target="#difference-from-traditional-modeling">Difference from Traditional Modeling</a></li>
  <li><a href="#the-cnn-breakthrough" id="toc-the-cnn-breakthrough" class="nav-link" data-scroll-target="#the-cnn-breakthrough">The CNN Breakthrough</a></li>
  </ul></li>
  <li><a href="#deep-learning-and-neural-networks" id="toc-deep-learning-and-neural-networks" class="nav-link" data-scroll-target="#deep-learning-and-neural-networks">Deep Learning and Neural Networks</a>
  <ul class="collapse">
  <li><a href="#convolutional-neural-networks" id="toc-convolutional-neural-networks" class="nav-link" data-scroll-target="#convolutional-neural-networks">Convolutional Neural Networks</a></li>
  <li><a href="#transfer-learning" id="toc-transfer-learning" class="nav-link" data-scroll-target="#transfer-learning">Transfer Learning</a></li>
  </ul></li>
  <li><a href="#problem-at-hand" id="toc-problem-at-hand" class="nav-link" data-scroll-target="#problem-at-hand">Problem At Hand</a></li>
  <li><a href="#typical-workflow" id="toc-typical-workflow" class="nav-link" data-scroll-target="#typical-workflow">Typical Workflow</a></li>
  <li><a href="#get-the-images" id="toc-get-the-images" class="nav-link" data-scroll-target="#get-the-images">1. Get the Images</a></li>
  <li><a href="#look-at-them" id="toc-look-at-them" class="nav-link" data-scroll-target="#look-at-them">2. Look at Them!</a></li>
  <li><a href="#release-the-loader" id="toc-release-the-loader" class="nav-link" data-scroll-target="#release-the-loader">3. Release the Loader!</a></li>
  <li><a href="#define-a-model" id="toc-define-a-model" class="nav-link" data-scroll-target="#define-a-model">4. Define A Model</a>
  <ul class="collapse">
  <li><a href="#head-of-a-cnn" id="toc-head-of-a-cnn" class="nav-link" data-scroll-target="#head-of-a-cnn">Head of A CNN</a></li>
  <li><a href="#model-hyperparameters" id="toc-model-hyperparameters" class="nav-link" data-scroll-target="#model-hyperparameters">Model Hyperparameters</a></li>
  </ul></li>
  <li><a href="#train-the-model" id="toc-train-the-model" class="nav-link" data-scroll-target="#train-the-model">5. Train the Model</a></li>
  <li><a href="#get-the-predictions" id="toc-get-the-predictions" class="nav-link" data-scroll-target="#get-the-predictions">6. Get the Predictions</a></li>
  <li><a href="#transfer-learning-1" id="toc-transfer-learning-1" class="nav-link" data-scroll-target="#transfer-learning-1">Transfer Learning</a></li>
  <li><a href="#experiment-tracking" id="toc-experiment-tracking" class="nav-link" data-scroll-target="#experiment-tracking">Experiment Tracking</a></li>
  <li><a href="#massive-improvement-using-transfer-learning" id="toc-massive-improvement-using-transfer-learning" class="nav-link" data-scroll-target="#massive-improvement-using-transfer-learning">Massive Improvement Using Transfer Learning</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">A Friendly ☺️ Introduction to CNNs with Keras</h1>
  <div class="quarto-categories">
    <div class="quarto-category">getting-started</div>
    <div class="quarto-category">deep-learning</div>
  </div>
  </div>

<div>
  <div class="description">
    A basic intro to CNNs, a code-only tutorial using keras
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Shubham Shinde </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 15, 2023</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="computer-vision" class="level2">
<h2 class="anchored" data-anchor-id="computer-vision">Computer Vision</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/computer_vision.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">Computer Vision</figcaption><p></p>
</figure>
</div>
<p>This was originally a <a href="https://www.kaggle.com/code/shindeshubham85/a-friendly-introduction-to-cnns-in-keras"><img src="assets/kaggle.png" class="img-fluid" style="width:10.0%"></a> notebook.</p>
<p>In a nutshell, CNNs are special deep learning architectures that have revolutionized the field of computer vision. Computer Vision is a field that is concerned about deriving information from images using computers. Some examples of computer vision include- Identifying whether a given image contains an item, like identifying a pedestrian in traffic, identifying cracks in an industrial machine, identifying if an X-Ray is abnormal. Self-Driving cars rely on computer vision algorithms, which are often CNNs. Filters on Instagram, face recognition systems, all use deep learning under the hood.</p>
<p>But some general types of computer vision problems are:</p>
<ul>
<li>Image Classification (Is this image of a cat?)</li>
<li>Object Detection (Is there a cat in this image, and WHERE exactly is it?)</li>
<li>Segmentation (give me the exact outline of the cat in this image, if it exists)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/tasks.png" class="img-fluid figure-img" style="width:40.0%"></p>
<p></p><figcaption class="figure-caption">Computer Vision Tasks</figcaption><p></p>
</figure>
</div>
<section id="difference-from-traditional-modeling" class="level3">
<h3 class="anchored" data-anchor-id="difference-from-traditional-modeling">Difference from Traditional Modeling</h3>
<p>If you’re here, it probably means you’re familiar with basic machine learning concepts- like training data, predictions, feature engineering, etc. on tabular data. However image data is different from tabular data due to having a different structure, hence traditional algorithms like random forest cannot be used for classifying images.</p>
</section>
<section id="the-cnn-breakthrough" class="level3">
<h3 class="anchored" data-anchor-id="the-cnn-breakthrough">The CNN Breakthrough</h3>
<p>This is where CNNs made the breakthrough, and achieved tremendous results on image data. Before CNNs, image analytics required a lot of feature engineering and pre-processing (tons of hand-made filters). CNNs outperformed all the traditional methods without requiring such feature engineering. CNNs learnt the features and filters by itself. All you had to do was feed a lot of data to the model.</p>
</section>
</section>
<section id="deep-learning-and-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="deep-learning-and-neural-networks">Deep Learning and Neural Networks</h2>
<p>CNN, that is, Convolutional Neural Networks are a subfield of neural networks, a family of algorithms. A neural network is a collection of nodes or neurons, where each neuron has a weight*. These weights are learnt during the training process such that the model is able to predict the output when input is given. When a lot of such neurons are stacked together, we get a neural network. A neural network with a lot of layers would be called deep neural network, a phenomenon which has driven majority of the AI success in the last decade.</p>
<p>In CNNs, the neurons are arranged and stacked in a manner suitable for images.</p>
<section id="convolutional-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-networks">Convolutional Neural Networks</h3>
<p>In CNN, we have filters (which are tiny 3x3 matrices) which “convolve” an image to get a transformed matrix. We won’t worry about the theory and filters here. All you need to know, that filters transform the image to a new matrix. This matrix is made smaller by a method called Pooling. These two operations create one Convolution Layer, and several such Layers create a CNN. This order isn’t mandatory, as we’ll see later.</p>
<p>This is a <a href="https://www.youtube.com/watch?v=YRhxdVk_sIs">nice animation</a> that showcases the convolution operation.</p>
<div data-align="center">
<iframe align="middle" width="790" height="440" src="https://www.youtube.com/embed/YRhxdVk_sIs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</div>
</section>
<section id="transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="transfer-learning">Transfer Learning</h3>
<p>There’s a neat trick in deep learning called transfer learning- which is covered at the end of the notebook in case you make it.</p>
<p>That’s quite a lot of theory, on to the problem at hand.</p>
</section>
</section>
<section id="problem-at-hand" class="level2">
<h2 class="anchored" data-anchor-id="problem-at-hand">Problem At Hand</h2>
<p>The task at hand is an image classification task. You’re given a ton of images that are either a cat image or a dog image. Now, if you give a new image, you should be able to predict if it’s of a dog or a cat.</p>
<p>We are going to train a CNN to do this. Using the keras library.</p>
</section>
<section id="typical-workflow" class="level2">
<h2 class="anchored" data-anchor-id="typical-workflow">Typical Workflow</h2>
<p>Typically when you work on a CNN task, this is how your notebook flow will look like: Whatever time you spend with CNNs, it will be in one of these sections.</p>
<ol type="1">
<li><strong>Get the Images</strong></li>
</ol>
<p>(collecting images itself can be either a herculean task or sometimes ready-made data is available, time and effort varies with dataset)</p>
<p>Difficulty Level: Varies Time Needed: Varies</p>
<ol start="2" type="1">
<li><strong>Look at the Images and the Targets</strong></li>
</ol>
<p>(see how the images actually look like, what are the classes, how many of them.)</p>
<ol start="3" type="1">
<li><strong>Create a Data Loader</strong></li>
</ol>
<p>(in most libraries you need a guy that reads the images and feeds to the model, and does the intermediate work- batching, augmentation, split, multiprocessing, etc. configuring this step will be a good chunk of your time )</p>
<ol start="4" type="1">
<li><strong>Define Your Model</strong></li>
</ol>
<p>(how many CNN layers? How many filters, the optimizer, the loss function? this could be as easy as downloading/pasting an existing model in ten minutes, or the experiments could go on forever)</p>
<ol start="5" type="1">
<li><strong>Train the Model</strong></li>
</ol>
<p>(now throw the dataloader function on the model and let it train. sit back and sip coffee.)</p>
<ol start="6" type="1">
<li><strong>Get The Predictions</strong></li>
</ol>
<p>(here you actually use the model. for some task, or just to check if it’s doing good. evaluating whether the model is giving good predictions can also be challenging in some use cases.)</p>
<ol start="7" type="1">
<li><strong>Debugging</strong></li>
</ol>
<p>If you keep it simple, load pre-built modules, the model will work. But there could be many possible problems that might arise in the task. These will be covered at the end.</p>
<p>::: {.cell _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ execution=‘{“iopub.execute_input”:“2023-01-07T11:37:46.774008Z”,“iopub.status.busy”:“2023-01-07T11:37:46.773068Z”,“iopub.status.idle”:“2023-01-07T11:37:52.956681Z”,“shell.execute_reply”:“2023-01-07T11:37:52.955647Z”}’ papermill=‘{“duration”:6.19509,“end_time”:“2023-01-07T11:37:52.959543”,“exception”:false,“start_time”:“2023-01-07T11:37:46.764453”,“status”:“completed”}’ tags=‘[]’ execution_count=1}</p>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.image <span class="im">import</span> ImageDataGenerator, load_img</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> plot_model</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> to_categorical</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>:::</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:37:52.977159Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:37:52.975428Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:37:53.924902Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:37:53.923709Z&quot;}" data-papermill="{&quot;duration&quot;:0.960419,&quot;end_time&quot;:&quot;2023-01-07T11:37:53.927312&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:37:52.966893&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls ..<span class="op">/</span><span class="bu">input</span><span class="op">/</span>dogs<span class="op">-</span>vs<span class="op">-</span>cats<span class="op">/</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># the images are in a zip file in this folder</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>sampleSubmission.csv  test1.zip  train.zip</code></pre>
</div>
</div>
</section>
<section id="get-the-images" class="level2">
<h2 class="anchored" data-anchor-id="get-the-images">1. Get the Images</h2>
<p>Extract the images from the zip file. Now there are two folders: train/ and test1/</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:37:53.959044Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:37:53.958255Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:10.454469Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:10.453237Z&quot;}" data-papermill="{&quot;duration&quot;:16.507658,&quot;end_time&quot;:&quot;2023-01-07T11:38:10.457557&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:37:53.949899&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(<span class="st">"../input/dogs-vs-cats/train.zip"</span>,<span class="st">"r"</span>) <span class="im">as</span> z:</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    z.extractall(<span class="st">"."</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(<span class="st">"../input/dogs-vs-cats/test1.zip"</span>,<span class="st">"r"</span>) <span class="im">as</span> z:</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    z.extractall(<span class="st">"."</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls <span class="op">/</span>kaggle<span class="op">/</span>working<span class="op">/</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__notebook__.ipynb  test1  train</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:10.480187Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:10.479766Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:10.598919Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:10.597850Z&quot;}" data-papermill="{&quot;duration&quot;:0.133456,&quot;end_time&quot;:&quot;2023-01-07T11:38:10.601783&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:10.468327&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># let's look at any five files in the train folder</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>glob.glob(<span class="st">"/kaggle/working/train/*.jpg"</span>)[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>['/kaggle/working/train/dog.8701.jpg',
 '/kaggle/working/train/dog.9481.jpg',
 '/kaggle/working/train/cat.104.jpg',
 '/kaggle/working/train/cat.8800.jpg',
 '/kaggle/working/train/dog.6199.jpg']</code></pre>
</div>
</div>
<p>You now notice that the label is encoded in the filename itself- cat or dog! We need to extract that to be able to train the model.</p>
<p>We are collecting each filename, and the corresponding label in a pandas dataframe (needed later)</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:10.645446Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:10.645005Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:10.800698Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:10.799509Z&quot;}" data-papermill="{&quot;duration&quot;:0.169767,&quot;end_time&quot;:&quot;2023-01-07T11:38:10.803124&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:10.633357&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>train_files <span class="op">=</span> glob.glob(<span class="st">"/kaggle/working/train/*.jpg"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>train_labels <span class="op">=</span> [i.strip(<span class="st">'/kaggle/working/train/'</span>)[:<span class="dv">3</span>] <span class="cf">for</span> i <span class="kw">in</span> train_files]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.DataFrame({<span class="st">'filename'</span>: train_files, <span class="st">'class'</span>: train_labels})</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>train_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>filename</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>/kaggle/working/train/dog.8701.jpg</td>
      <td>dog</td>
    </tr>
    <tr>
      <th>1</th>
      <td>/kaggle/working/train/dog.9481.jpg</td>
      <td>dog</td>
    </tr>
    <tr>
      <th>2</th>
      <td>/kaggle/working/train/cat.104.jpg</td>
      <td>cat</td>
    </tr>
    <tr>
      <th>3</th>
      <td>/kaggle/working/train/cat.8800.jpg</td>
      <td>cat</td>
    </tr>
    <tr>
      <th>4</th>
      <td>/kaggle/working/train/dog.6199.jpg</td>
      <td>dog</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>First step is done- we have the images, and we have the labels. Let’s move to the second step.</p>
</section>
<section id="look-at-them" class="level2">
<h2 class="anchored" data-anchor-id="look-at-them">2. Look at Them!</h2>
<p>We now observe what the images look like. We’ll look at four random images from the data.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:10.848325Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:10.848020Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:11.537208Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:11.536377Z&quot;}" data-papermill="{&quot;duration&quot;:0.704933,&quot;end_time&quot;:&quot;2023-01-07T11:38:11.544590&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:10.839657&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>axs <span class="op">=</span> axs.ravel()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="dv">4</span>):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> random.choice(train_df.index)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    axs[i].imshow(Image.<span class="bu">open</span>(train_df[<span class="st">'filename'</span>][idx]))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    axs[i].set_title(train_df[<span class="st">'class'</span>][idx])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="keras_cnns_intro_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This is a pretty clean dataset- that’s good. The subjects of the image are in center, occupy a majority of the image, no blurriness or anything. (Ideally you’d look at more images than a dozen tho,:) )</p>
<p>You might’ve noticed that the dimensions of the images are not constant, they vary a lot. This will be a problem for the CNN- it expects images of a fixed size! How do we take care of it? We don’t, our data loader guy will do it for us.</p>
<p>(Well, sometimes we might want to do it ourselves, if we think the resizing needs extra attention- but in this case, we’ll let it be automated.)</p>
</section>
<section id="release-the-loader" class="level2">
<h2 class="anchored" data-anchor-id="release-the-loader">3. Release the Loader!</h2>
<p>Dataloaders are the unsung heroes of the CNN world- they take care of a lot of nasty work that would be a nightmare if we had to do it by hand. What they essentially do is simple- read the data from the disk, and feed to the model. But under the hood they take care of many things, like…</p>
<ol type="1">
<li>Resizing, as we discussed. Ensuring that each image is of a fixed size.</li>
<li>Batching. Feeding images one-by-one to the model is tedious, would take a lot of time. It’s better to feed a large number of them at once (as much your computer will allow)</li>
<li>Label Encoding. Computers don’t understand string like ‘cat’ or ‘dog’, you have to convert them to numbers like 0 or 1.</li>
<li>Data Augmentation. Create more images by slightly modifying an image (flipping it, rotating it teeny bit, adding some spots, etc.)</li>
<li>Validation Split. Keras now has support for validation splitting.</li>
<li>Sometimes the data is too large to fit into memory (10+ GB, say), then loaders can iterate through the dataset on disk chunk-by-chunk instead of loading everything at once.</li>
</ol>
<p>We are using keras’s <code>ImageDataGenerator</code> to create our training data loader.</p>
<p>Two steps:</p>
<ol type="1">
<li>Define a <code>ImageDataGenerator</code> instance, and specify the augmentation strategies.</li>
<li>Create a generator from this instance by specifying the image file paths and labels. Pass this generator to the model for training.</li>
</ol>
<p>In pytorch there’s <code>torch.utils.data.Dataset</code> and<code>torch.utils.data.DataLoader</code>. Sometimes you may need to define a custom dataloader, but the default is good enough for most use cases.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:11.626785Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:11.626434Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:11.632274Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:11.631254Z&quot;}" data-papermill="{&quot;duration&quot;:0.022781,&quot;end_time&quot;:&quot;2023-01-07T11:38:11.634597&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:11.611816&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>train_datagen <span class="op">=</span> ImageDataGenerator(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    rotation_range<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    horizontal_flip<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    shear_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    zoom_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># create a image data generator object. </span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># all these are data augmentation parameters.</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># now let's specify the image size to which each image will be resized to</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>img_height, img_width <span class="op">=</span> <span class="dv">224</span>, <span class="dv">224</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There are two ways to create data generators/loaders from above instance. I recommend going through the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator">ImageDataGenerator API page</a>, but the two methods are:</p>
<ol type="1">
<li>Flow from Dataframe (here, you can contain the filenames and labels in a pandas dataframe, and pass the dataframe), we are using this, remember the dataframe we created earlier?</li>
<li>Flow from Directory (here, you can pass the path of a directory. This directory should contain subfolders corresponding to each class. You will have to rearrange your directory so that it looks like this.</li>
</ol>
<pre><code>Train/
---| Dog/
   ---| Dog1.jpg
   ---| Dog1.jpg
---| Cat/
   ---| Cat1.jpg
   ---| Cat2.jpg
Val/
---| Dog/
   ---| Dog5.jpg
   ---| Dog6.jpg
---| Cat/
   ---| Cat7.jpg
   ---| Cat8.jpg</code></pre>
<p>Since we are using method1, we will not be rearranging the folders.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:11.689506Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:11.689194Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:12.066046Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:12.064842Z&quot;}" data-papermill="{&quot;duration&quot;:0.393957,&quot;end_time&quot;:&quot;2023-01-07T11:38:12.068358&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:11.674401&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train_generator <span class="op">=</span> train_datagen.flow_from_dataframe(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    train_df,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    target_size<span class="op">=</span>(img_height, img_width),</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    class_mode<span class="op">=</span><span class="st">'categorical'</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">'training'</span>) <span class="co"># set as training data</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># remember we put 0.2 validation split while defining ImageDataGenerator?</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>validation_generator <span class="op">=</span> train_datagen.flow_from_dataframe(</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    train_df, <span class="co"># same directory as training data</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    target_size<span class="op">=</span>(img_height, img_width),</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    class_mode<span class="op">=</span><span class="st">'categorical'</span>,</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">'validation'</span>) <span class="co"># set as validation data</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Class Indices:"</span>, train_generator.class_indices)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 20000 validated image filenames belonging to 2 classes.
Found 5000 validated image filenames belonging to 2 classes.
Class Indices: {'cat': 0, 'dog': 1}</code></pre>
</div>
</div>
</section>
<section id="define-a-model" class="level2">
<h2 class="anchored" data-anchor-id="define-a-model">4. Define A Model</h2>
<p>Now we come to the meaty part- defining the CNN network, the engine of our application. As we discussed earlier, we are going to define a series of Convolution Layers, and each convolution layer consists of a convolution operation followed by a max pool layer.</p>
<p>This order is not mandatory- you can have two Convolution operations followed by one max pool, or three, or an average pool- that’s the neat part of neural networks, they’re so adaptable and malleable, and the best configurations are often found out by trial and error. In this case, we are going with the wisdom of our elders, and go by this order.</p>
<section id="head-of-a-cnn" class="level3">
<h3 class="anchored" data-anchor-id="head-of-a-cnn">Head of A CNN</h3>
<p>As we apply more Conv Layers, you will get a transformed matrix of somesize x somesize. But what good is a matrix to us? We need a simple answer- 0 or 1! In order to get this answer, we “flatten” the final matrix to a single vector of size somesize-times-2 x 1. Then we pass it through more neural network neurons to get a single neuron at the end. This neuron’s output is constrained between 0 and 1. This is our final probability! If it’s greater than 0.5, the prediction is 1, if not, it’s 0.</p>
<p>If you have more than 2 classes, like predicting a digit. In this case, there would be ten neurons at the end. Each of their output would be the probability of that class.</p>
</section>
<section id="model-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="model-hyperparameters">Model Hyperparameters</h3>
<p>Apart from number of Conv layers, there are other design choices while designing a CNN- they include selecting the optimizer, the learning rate, the loss function, the number of filters. For an introductory notebook, discussion on those is not necessary.</p>
<p>What’s important to note: passing the input shape to the first layer. Ensuring that the last layer corresponds to the number of classes.</p>
<p>Try tinkering with this configuration to see how the results change. Try using only one Conv Layer, reducing number of filters, increasing number of filters, etc.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:12.123985Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:12.123655Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:15.006157Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:15.004003Z&quot;}" data-papermill="{&quot;duration&quot;:2.899066,&quot;end_time&quot;:&quot;2023-01-07T11:38:15.008260&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:12.109194&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, </span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>                 input_shape<span class="op">=</span>(img_width, img_height, <span class="dv">3</span>)))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 32 here means this layer will contain 32 filters of size 3x3 being learnt</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># batchnorm is a useful layer that helps in convergence</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># maxpooling will reduce the size of the image</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># dropout is used for regularization, ensuring that model doesn't overfit</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co"># convolutional block is complete. now on to defining the "head"</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="co"># first flatten the matrix to get a single array</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="co"># adding a dense hidden layer of neurons</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>model.add(BatchNormalization())</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.5</span>))</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="co"># finally the output layer with neurons=number of classes and softmax activation</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)) <span class="co"># 2 because we have cat and dog classes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-01-07 11:38:12.212718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:12.342711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:12.343593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:12.345511: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-07 11:38:12.345912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:12.346654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:12.347302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:14.495879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:14.496731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:14.497497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 11:38:14.498130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -&gt; device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0</code></pre>
</div>
</div>
<p>Let’s visualize how our network looks like, and what the shapes of input and output at each layer.</p>
<p>The shapes of input and output can be useful for debugging. If there’s a mismatch between output of one layer and input of next, model will throw up error.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:15.065000Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:15.064096Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:15.999864Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:15.998734Z&quot;}" data-papermill="{&quot;duration&quot;:0.952978,&quot;end_time&quot;:&quot;2023-01-07T11:38:16.002149&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:15.049171&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>, show_layer_names<span class="op">=</span><span class="va">False</span>, dpi<span class="op">=</span><span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<p><img src="keras_cnns_intro_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:16.036028Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:16.034444Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T11:38:16.050816Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T11:38:16.049980Z&quot;}" data-papermill="{&quot;duration&quot;:0.034609,&quot;end_time&quot;:&quot;2023-01-07T11:38:16.052796&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:16.018187&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compile the model while defining a loss, optimizer, and metrics to track, </span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and add callbacks if necessary</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>              optimizer<span class="op">=</span><span class="st">'adam'</span>, </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="train-the-model" class="level2">
<h2 class="anchored" data-anchor-id="train-the-model">5. Train the Model</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T11:38:16.085075Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T11:38:16.083469Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:10.273935Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:10.272894Z&quot;}" data-papermill="{&quot;duration&quot;:3474.20881,&quot;end_time&quot;:&quot;2023-01-07T12:36:10.276450&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T11:38:16.067640&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>epochs<span class="op">=</span><span class="dv">10</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    train_generator, </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>validation_generator,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-01-07 11:38:16.953970: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/10</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-01-07 11:38:20.190526: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>313/313 [==============================] - 334s 1s/step - loss: 0.7747 - accuracy: 0.6353 - val_loss: 1.8673 - val_accuracy: 0.4876
Epoch 2/10
313/313 [==============================] - 324s 1s/step - loss: 0.5450 - accuracy: 0.7254 - val_loss: 0.5757 - val_accuracy: 0.7110
Epoch 3/10
313/313 [==============================] - 325s 1s/step - loss: 0.4821 - accuracy: 0.7671 - val_loss: 0.4726 - val_accuracy: 0.7732
Epoch 4/10
313/313 [==============================] - 326s 1s/step - loss: 0.4332 - accuracy: 0.7987 - val_loss: 0.4627 - val_accuracy: 0.7800
Epoch 5/10
313/313 [==============================] - 323s 1s/step - loss: 0.3989 - accuracy: 0.8184 - val_loss: 0.4141 - val_accuracy: 0.8128
Epoch 6/10
313/313 [==============================] - 322s 1s/step - loss: 0.3702 - accuracy: 0.8349 - val_loss: 0.4598 - val_accuracy: 0.7822
Epoch 7/10
313/313 [==============================] - 323s 1s/step - loss: 0.3409 - accuracy: 0.8484 - val_loss: 0.3489 - val_accuracy: 0.8442
Epoch 8/10
313/313 [==============================] - 324s 1s/step - loss: 0.3169 - accuracy: 0.8641 - val_loss: 0.3765 - val_accuracy: 0.8478
Epoch 9/10
313/313 [==============================] - 323s 1s/step - loss: 0.3124 - accuracy: 0.8629 - val_loss: 0.4741 - val_accuracy: 0.7906
Epoch 10/10
313/313 [==============================] - 324s 1s/step - loss: 0.2925 - accuracy: 0.8721 - val_loss: 0.6446 - val_accuracy: 0.7484</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:10.625999Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:10.625243Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:11.152627Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:11.151742Z&quot;}" data-papermill="{&quot;duration&quot;:0.703214,&quot;end_time&quot;:&quot;2023-01-07T12:36:11.154843&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:10.451629&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="13">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(history):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    ax1.plot(history.history[<span class="st">'loss'</span>], color<span class="op">=</span><span class="st">'b'</span>, label<span class="op">=</span><span class="st">"Training loss"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    ax1.plot(history.history[<span class="st">'val_loss'</span>], color<span class="op">=</span><span class="st">'r'</span>, label<span class="op">=</span><span class="st">"validation loss"</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks(np.arange(<span class="dv">1</span>, epochs, <span class="dv">1</span>))</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    ax2.plot(history.history[<span class="st">'accuracy'</span>], color<span class="op">=</span><span class="st">'b'</span>, label<span class="op">=</span><span class="st">"Training accuracy"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    ax2.plot(history.history[<span class="st">'val_accuracy'</span>], color<span class="op">=</span><span class="st">'r'</span>,label<span class="op">=</span><span class="st">"Validation accuracy"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    ax2.set_xticks(np.arange(<span class="dv">1</span>, epochs, <span class="dv">1</span>))</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    legend <span class="op">=</span> plt.legend(loc<span class="op">=</span><span class="st">'best'</span>, shadow<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>plot_loss(history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="keras_cnns_intro_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="get-the-predictions" class="level2">
<h2 class="anchored" data-anchor-id="get-the-predictions">6. Get the Predictions</h2>
<p>Now that the model is trained, let’s check if the model is giving us good predictions, by trying it out on the test data.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:11.897834Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:11.897458Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:12.023708Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:12.022626Z&quot;}" data-papermill="{&quot;duration&quot;:0.353908,&quot;end_time&quot;:&quot;2023-01-07T12:36:12.026546&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:11.672638&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="14">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>test_files <span class="op">=</span> glob.glob(<span class="st">'/kaggle/working/test1/*.jpg'</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.DataFrame({<span class="st">'filename'</span>: test_files})</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>test_gen <span class="op">=</span> ImageDataGenerator(rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>test_generator <span class="op">=</span> test_gen.flow_from_dataframe(</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    test_df, </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    x_col<span class="op">=</span><span class="st">'filename'</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    y_col<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    class_mode<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    target_size<span class="op">=</span>(img_height, img_width),</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 12500 validated image filenames.</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:12.374320Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:12.373921Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:19.003695Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:19.002898Z&quot;}" data-papermill="{&quot;duration&quot;:6.812598,&quot;end_time&quot;:&quot;2023-01-07T12:36:19.011415&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:12.198817&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_predictions(test_generator, model):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">15</span>):</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">5</span>, <span class="dv">3</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch <span class="kw">in</span> test_generator:</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>            prediction <span class="op">=</span> model.predict(X_batch)[<span class="dv">0</span>]</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> X_batch[<span class="dv">0</span>]</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>            plt.imshow(image)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="st">'cat'</span> <span class="cf">if</span> np.argmax(prediction)<span class="op">==</span><span class="dv">0</span> <span class="cf">else</span> <span class="st">"dog"</span>)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>visualize_predictions(test_generator, model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="keras_cnns_intro_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="transfer-learning-1" class="level2">
<h2 class="anchored" data-anchor-id="transfer-learning-1">Transfer Learning</h2>
<p>If you made it here, we’ll talk about deep learning’s most important tricks- transfer learning!</p>
<p>Neural networks are notoriously data hungry- they can eat millions of images and digest them to be able to generalize upon their features. In this case, what if you don’t have millions of images?</p>
<p>In this case, you use a model that has been trained on millions of images. And take it as your starting point. And train your model from them. Those massive datasets don’t necessarily have to be related to your image classes.</p>
<p>There are many publicly available models like resnet, xception, convnext (particular architectures of CNNs) trained on ImageNet dataset (a very large image dataset with 100+ different classes). You can simply download them, and use it for your task (classifying dogs), and it will work much better than defining a model from new.</p>
<p>We’ll implement a model using transfer learning below.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:19.734242Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:19.733878Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:21.707074Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:21.706057Z&quot;}" data-papermill="{&quot;duration&quot;:2.157794,&quot;end_time&quot;:&quot;2023-01-07T12:36:21.710237&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:19.552443&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.applications <span class="im">import</span> ResNet50, Xception</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> Input</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Model</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ResNet50 is our "backbone" of sorts, a CNN architecture </span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># pretrained on the imagenet dataset</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># we are only taking the CNN portion of it (include_top = False)</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># and dropping the dense layer, we'll initialize a dense network of our own</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>basemodel <span class="op">=</span> Xception(include_top <span class="op">=</span> <span class="va">False</span>, </span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>                   weights <span class="op">=</span> <span class="st">'imagenet'</span>,</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>                  input_shape<span class="op">=</span>(img_height, img_width, <span class="dv">3</span>))</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>basemodel.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co"># use the output of the baseModel to create a "head"</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>headModel <span class="op">=</span> basemodel.output</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>headModel <span class="op">=</span> MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))(headModel)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>headModel <span class="op">=</span> Flatten(name<span class="op">=</span><span class="st">"flatten"</span>)(headModel)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>headModel <span class="op">=</span> Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(headModel)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>headModel <span class="op">=</span> Dropout(<span class="fl">0.8</span>)(headModel)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># headModel = Dense(32, activation="relu")(headModel)</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="co"># headModel = Dropout(0.5)(headModel)</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>headModel <span class="op">=</span> Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)(headModel)</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="co"># at the end, we'll have two neurons, for two of the classes</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="co"># we're "disabling" the backbone, and only training the head for this task</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="co"># we're assuming that the backbone is already sufficiently trained to generate</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="co"># features from images like ours.</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a><span class="co"># we can also "disable" all CNN layers except last 4</span></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="co"># create a model object</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(inputs<span class="op">=</span>basemodel.<span class="bu">input</span>, outputs<span class="op">=</span>headModel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5
83689472/83683744 [==============================] - 1s 0us/step
83697664/83683744 [==============================] - 1s 0us/step</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:22.271148Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:22.270579Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:22.275448Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:22.274642Z&quot;}" data-papermill="{&quot;duration&quot;:0.294383,&quot;end_time&quot;:&quot;2023-01-07T12:36:22.279392&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:21.985009&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot_model(model, show_shapes=True, show_layer_names=False, dpi=60)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="experiment-tracking" class="level2">
<h2 class="anchored" data-anchor-id="experiment-tracking">Experiment Tracking</h2>
<p>In earlier case, we plotted our losses and metrics after the training was done, manually using matplotlib. But there are tools available using which we can observe real-time how our training is progressing. They also log system metrics like GPU usage, and can keep track of multiple experiments, hyperparameters etc. One such tool is wandb.ai, using which you can track your model even on phone as it’s running in background.</p>
<p>Using it is very simple, signup on <a href="wandb.ai">wandb.ai</a>, and add only few lines of code. Get the API token, and go through <a href="https://www.kaggle.com/general/209530">this discussion</a> on how to add it as a kaggle secret.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:23.178436Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:23.178088Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:25.450810Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:25.449820Z&quot;}" data-papermill="{&quot;duration&quot;:2.457549,&quot;end_time&quot;:&quot;2023-01-07T12:36:25.453033&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:22.995484&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="18">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>use_wandb <span class="op">=</span> <span class="va">True</span> <span class="co"># set to false if you don't want to use wandb for tracking</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> use_wandb:</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> kaggle_secrets <span class="im">import</span> UserSecretsClient</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> wandb</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> wandb.keras <span class="im">import</span> WandbCallback</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    user_secrets <span class="op">=</span> UserSecretsClient()</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    wandb_api <span class="op">=</span> user_secrets.get_secret(<span class="st">"wandb_api"</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    wandb.login(key<span class="op">=</span>wandb_api)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin
wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.
wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.
wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:25.823097Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:25.822725Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:32.713179Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:32.712167Z&quot;}" data-papermill="{&quot;duration&quot;:7.080441,&quot;end_time&quot;:&quot;2023-01-07T12:36:32.715909&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:25.635468&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="19">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> use_wandb:</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    wandb.init(project<span class="op">=</span><span class="st">"keras_cats_and_dogs"</span>, config<span class="op">=</span>{<span class="st">"batch_size"</span>: batch_size})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: Currently logged in as: shindeshu. Use `wandb login --relogin` to force relogin</code></pre>
</div>
<div class="cell-output cell-output-display">
wandb version 0.13.7 is available!  To upgrade, please run:
 $ pip install wandb --upgrade
</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.12.21
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/kaggle/working/wandb/run-20230107_123626-2bw5qpbs</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/shindeshu/keras_cats_and_dogs/runs/2bw5qpbs" target="_blank">fancy-plant-6</a></strong> to <a href="https://wandb.ai/shindeshu/keras_cats_and_dogs" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:33.344004Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:33.343415Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T12:36:33.365175Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T12:36:33.364327Z&quot;}" data-papermill="{&quot;duration&quot;:0.366902,&quot;end_time&quot;:&quot;2023-01-07T12:36:33.367902&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:33.001000&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>              optimizer<span class="op">=</span>opt, </span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T12:36:33.938057Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T12:36:33.937490Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T13:06:34.195009Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T13:06:34.194053Z&quot;}" data-papermill="{&quot;duration&quot;:1800.546907,&quot;end_time&quot;:&quot;2023-01-07T13:06:34.197419&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T12:36:33.650512&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="21">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>epochs<span class="op">=</span><span class="dv">5</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>callbacks<span class="op">=</span>[EarlyStopping(monitor<span class="op">=</span><span class="st">'loss'</span>, patience<span class="op">=</span><span class="dv">2</span>), ]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> use_wandb: callbacks.append(WandbCallback())</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit_generator(</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    train_generator,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>validation_generator,</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>callbacks,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&amp;B files and the SavedModel as W&amp;B Artifacts.
/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`Model.fit_generator` is deprecated and '
2023-01-07 12:36:46.761375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 12:36:46.761921: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 1
2023-01-07 12:36:46.762185: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session
2023-01-07 12:36:46.765305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 12:36:46.765841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 12:36:46.766331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 12:36:46.766954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 12:36:46.767464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-01-07 12:36:46.767852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -&gt; device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
2023-01-07 12:36:46.787714: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize
  function_optimizer: function_optimizer did nothing. time = 0.01ms.
  function_optimizer: function_optimizer did nothing. time = 0.002ms.
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
313/313 [==============================] - 350s 1s/step - loss: 0.1106 - accuracy: 0.9637 - val_loss: 0.0460 - val_accuracy: 0.9844</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  category=CustomMaskWarning)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 2/5
313/313 [==============================] - 335s 1s/step - loss: 0.0764 - accuracy: 0.9768 - val_loss: 0.0479 - val_accuracy: 0.9828
Epoch 3/5
313/313 [==============================] - 334s 1s/step - loss: 0.0690 - accuracy: 0.9771 - val_loss: 0.0380 - val_accuracy: 0.9844
Epoch 4/5
313/313 [==============================] - 331s 1s/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 0.0399 - val_accuracy: 0.9854
Epoch 5/5
313/313 [==============================] - 337s 1s/step - loss: 0.0629 - accuracy: 0.9777 - val_loss: 0.0380 - val_accuracy: 0.9836</code></pre>
</div>
</div>
</section>
<section id="massive-improvement-using-transfer-learning" class="level2">
<h2 class="anchored" data-anchor-id="massive-improvement-using-transfer-learning">Massive Improvement Using Transfer Learning</h2>
<p>When we defined a custom model earlier, the best validation accuracy we got after 10 epochs was <strong>85%</strong>.</p>
<p>Here, by using a pre-trained model, our validation accuracy after 1 epoch is as high as <strong>98%</strong>!</p>
<p>As we can see, using a pre-trained model can really boost our performance with minimal training efforts.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T13:06:35.271404Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T13:06:35.271028Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T13:06:35.565654Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T13:06:35.564802Z&quot;}" data-papermill="{&quot;duration&quot;:0.561439,&quot;end_time&quot;:&quot;2023-01-07T13:06:35.567660&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T13:06:35.006221&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="22">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>plot_loss(history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="keras_cnns_intro_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-01-07T13:06:36.099744Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-01-07T13:06:36.099399Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-01-07T13:06:46.136502Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-01-07T13:06:46.135704Z&quot;}" data-papermill="{&quot;duration&quot;:10.306872,&quot;end_time&quot;:&quot;2023-01-07T13:06:46.141786&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-01-07T13:06:35.834914&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]" data-execution_count="23">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>visualize_predictions(test_generator, model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="keras_cnns_intro_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>